# TRASE API

[![Build Status](https://travis-ci.org/Vizzuality/trase-api.svg?branch=master)](https://travis-ci.org/Vizzuality/trase-api)

API for the new [Trase](http://trase.earth) functionalities

## Requirements

This project uses:
- Ruby 2.4.0
- Rails 5.0
- PostgreSQL 9.x with `intarray` and `tablefunc` extensions

It also uses [Git Large File Storage](https://git-lfs.github.com/) to store big files.

## Deployment

We use Capistrano as a deployment tool. Refer to its documentation for more info

## Test

```
RAILS_ENV=test rake db:drop db:create db:structure:load
bundle exec rspec spec
```

## Gold master tests

There are 2 rake tasks:

- `bundle exec rake gold_master:record` - this one should be re-run when `spec/support/gold_master_urls.yml` is updated. It records the gold master responses for all the urls and zips them in `spec/support/gold_master.zip`. It should be run using the pre-revamp version of the backend code and database:
    * https://github.com/sei-international/TRASE/releases/tag/pre-revamp
    * https://github.com/Vizzuality/trase-api/releases/tag/pre-revamp
    * Note: some responses are huge, over 1 MB. They're zipped and stored using GLFS.
- `bundle exec rake gold_master:test` - this one collects responses as generated by the current version of the code and compares with the gold master using json & csv diffing tools. It's intended to be used with the same version of the database as the gold master.
  * Note: the responses are stored uncompressed in `tmp/actual` and are not cleaned after the tests have run.

Both tasks are parametrised by same env variables to specify the hosts on which to run, when running in local environment this is going to be something like:

```
GOLD_MASTER_HOST_V1=http://localhost:8080
GOLD_MASTER_HOST_V2=http://localhost:3000
GOLD_MASTER_HOST_V3=http://localhost:3000
```

## Database tuning

This is a useful post: [Performance Tuning Queries in PostgreSQL](https://www.geekytidbits.com/performance-tuning-postgres/)

Always use either in production or an equivalent staging environment. No point running in local environment.

### Enabling statistics collection in PostgreSQL
In the target database:

`CREATE EXTENSION pg_stat_statements;`

In postgresql.conf:

`
shared_preload_libraries = 'pg_stat_statements'         # (change requires restart)
pg_stat_statements.max = 10000
pg_stat_statements.track = all
`

Restart postgres server. Wait for usage statistics to be collected, then run this for list of longest running queries:

`SELECT * FROM pg_stat_statements ORDER BY total_time DESC;`

https://www.postgresql.org/docs/current/static/pgstatstatements.html

### Identifying missing indexes

`
SELECT relname, seq_scan-idx_scan AS too_much_seq, CASE WHEN seq_scan-idx_scan>0 THEN 'Missing Index?' ELSE 'OK' END, pg_relation_size(relname::regclass) AS rel_size, seq_scan, idx_scan FROM pg_stat_all_tables WHERE schemaname='public' AND pg_relation_size(relname::regclass)>80000 ORDER BY too_much_seq DESC;
`

### Identifying unused indexes

`
SELECT indexrelid::regclass as index, relid::regclass as table, 'DROP INDEX ' || indexrelid::regclass || ';' as drop_statement FROM pg_stat_user_indexes JOIN pg_index USING (indexrelid) WHERE idx_scan = 0 AND indisunique is false;
`
